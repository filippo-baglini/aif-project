{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69860168",
   "metadata": {},
   "source": [
    "# Project Report: AIF Project\n",
    "\n",
    "## Introduction\n",
    "    \n",
    "The AIF project, hosted on [GitHub](https://github.com/filippo-baglini/aif-project), aims to develop an intelligent agent for the MiniGrid environment, a highly customizable discrete-action environment within the Gymnasium library. \n",
    "\n",
    "Gymnasium is a Python framework designed for creating and testing simulated environments for reinforcement learning, offering a variety of pre-made scenarios for developing and benchmarking AI algorithms. MiniGrid, one of these environments, features a grid-based layout where the agent, represented as a triangle, interacts with objects like doors, keys, and boxes to navigate various challenges. \n",
    "Its high degree of configurability makes it an ideal platform for AI experimentation and customization.\n",
    "    \n",
    "The AIF Project aims to develop a custom AI agent for the MiniGrid environment, focusing specifically on a subset of scenarios known as BabyAI levels. BabyAI, a predecessor of the current MiniGrid library, features static, non-resetting obstacles that provide a simpler and more controlled framework for evaluating and training agents on grid-world tasks. This reduced complexity makes BabyAI levels particularly well-suited for designing and testing a custom utility-based agent. The project seeks to demonstrate the agent's capabilities by competing against an existing AI agent developed by the creators of the MiniGrid library, showcasing its efficiency and effectiveness in solving BabyAI tasks.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debf08d6",
   "metadata": {},
   "source": [
    "## Methodology\n",
    "This project leverages Python and various AI algorithms to interact with the BabyAI environment. The primary objective is to develop a general-purpose agent capable of solving all 92 tasks provided by the BabyAI library. Additionally, the project emphasizes optimizing the agent's performance by implementing strategies and custom heuristics designed to minimize the number of steps needed to complete each task, ensuring both efficiency and effectiveness across all challenges.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734ab991",
   "metadata": {},
   "source": [
    "### Needed to overcome the Key challenges include:\n",
    "\n",
    "1. **Limited Observability**\n",
    "    - The agent's restricted field of view provides incomplete information about the goal location\n",
    "3. **Efficient Navigation**\n",
    "    - Custom algorithms and heuristics ensure the agent moves efficiently through the environment\n",
    "5. **Dynamic Planning**\n",
    "    - The agent must plan online to handle subgoals and avoid getting stuck or hidden while reaching the main goal\n",
    "7. **Multiple Mission Handling**\n",
    "    - Tasks often involve multiple goals within a single mission\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2035a12f",
   "metadata": {},
   "source": [
    "## Initial Approach\n",
    "\n",
    "We initially focused on tackling simpler environments by first ensuring the agent could successfully complete them in any amount of steps and then gradually optimizing its actions to minimize the number of steps required.\n",
    "\n",
    "### Performance Metric\n",
    "But what exactly is defined as a *step* for our agent?\n",
    "A step represents an individual action taken by the agent, such as:\n",
    "- Moving forward to the next cell.\n",
    "- Rotating to change direction.\n",
    "- Picking up an object.\n",
    "\n",
    "Each step carries a cost, presenting the challenge of planning every action carefully to maximize efficiency.\n",
    "### Basic Strategy and Algorithms\n",
    "To handle simpler levels, we implemented the following approach:\n",
    "\n",
    "1. **Internal State Representation**  \n",
    "   - The agent maintains an internal map of what it has seen and remembers previously observed areas. This internal state allows the agent to track its surroundings effectively.\n",
    "2. **Exploration Strategy**\n",
    "   - The agent performs a visual scan of its current field of view to locate the target specified in the mission.\n",
    "   - If the target is not visible, the agent moves toward a **frontier cell** a cell located at the edge of the currently explored map.  \n",
    "   - The frontier cell is selected using a custom Manhattan distance heuristic that penalizes frontiers blocked by obstacles such as doors or walls. This ensures the agent selects a strategic frontier, minimizing wasted steps while exploring new areas.  \n",
    "3. **Pathfinding with A\\* and Manhattan Distance**  \n",
    "   - If the target has been identified, or we choose to move to a frontier cell the agent uses the A\\* search algorithm to compute the optimal path, utilizing the Manhattan heuristic to estimate distances.  \n",
    "   - Obstacles such as closed doors, lava tiles, and walls are considered during path computation to ensure safe and efficient navigation.\n",
    "\n",
    "\n",
    "By combining these strategies, the agent is able to handle simple environments effectively and efficiently.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47ffa63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def a_star_search(self, target):\n",
    "        \"\"\"\n",
    "        A* search algorithm for a grid.\n",
    "        \n",
    "        grid: 2D list representing the environment (0: free space, 1: obstacle).\n",
    "        start: Tuple (x, y) for the start position.\n",
    "        goal: Tuple (x, y) for the goal position.\n",
    "        \n",
    "        Returns the best path as a list of (x, y) tuples or None if no path exists.\n",
    "        \"\"\"\n",
    "\n",
    "        # Priority queue for open set\n",
    "        open_set = []\n",
    "        heapq.heappush(open_set, (0, self.pos))  # (f-score, cell)\n",
    "\n",
    "        # g-scores (costs to reach each cell)\n",
    "        g_score = {self.pos: 0}\n",
    "        f_score = {self.pos: manhattan_distance(self.pos, target)}\n",
    "        # Path tracking\n",
    "        came_from = {}\n",
    "\n",
    "        while open_set:\n",
    "            \n",
    "            # Pop the cell with the lowest f-score\n",
    "            _, current = heapq.heappop(open_set)\n",
    "\n",
    "            # Goal reached\n",
    "            if current == target:\n",
    "                # Reconstruct path\n",
    "                path = []\n",
    "                while current in came_from:\n",
    "                    path.append(current)\n",
    "                    current = came_from[current]\n",
    "                return path[::-1]  # Reverse the path\n",
    "\n",
    "            # Explore neighbors\n",
    "            for neighbor in self.neighbors(current):\n",
    "\n",
    "                if (self.vis_obs[neighbor[0], neighbor[1]][0] in (2, 9) or (self.vis_obs[neighbor[0], neighbor[1]][0] == 0 and neighbor != target)):\n",
    "                    continue\n",
    "                \n",
    "                else:\n",
    "                    # Check if a better direction is already faced (this is where your rotation logic applies)\n",
    "                    direction_to_cell = (neighbor[0] - current[0], neighbor[1] - current[1])\n",
    "                    if np.array_equal(direction_to_cell, np.array(self.f_vec)):\n",
    "                        if(self.vis_obs[neighbor[0], neighbor[1]][0] in (5, 6, 7)):\n",
    "                            if self.carrying:\n",
    "                                tentative_g = g_score[current] + 5 #Rotate, drop the carried item, rotate, pick up, move forward\n",
    "                            else:\n",
    "                                tentative_g = g_score[current] + 2 #Pick up the item and then move forward\n",
    "                        else:\n",
    "                        # No rotation needed, just moving forward\n",
    "                            tentative_g = g_score[current] + 1  # Moving forward\n",
    "                    elif np.array_equal(direction_to_cell, -np.array(self.f_vec)):\n",
    "                        if(self.vis_obs[neighbor[0], neighbor[1]][0] in (5, 6, 7)):\n",
    "                            if self.carrying:\n",
    "                                tentative_g = g_score[current] + 7\n",
    "                            else:  \n",
    "                                tentative_g = g_score[current] + 4\n",
    "                        #cell behind us, 2 rotaton and 1 forward\n",
    "                        else:\n",
    "                            tentative_g =  g_score[current] + 3\n",
    "                    else:\n",
    "                        if(self.vis_obs[neighbor[0], neighbor[1]][0] in (5, 6, 7)):\n",
    "                            if self.carrying:\n",
    "                                tentative_g = g_score[current] + 6\n",
    "                            else:\n",
    "                                tentative_g = g_score[current] + 3\n",
    "                        # Rotation + move forward (rotate 90 degrees)\n",
    "                        else:\n",
    "                            tentative_g = g_score[current] + 2  # Rotate and move\n",
    "\n",
    "                    if neighbor not in g_score or tentative_g < g_score[neighbor]:\n",
    "                        # Update g-score and f-score\n",
    "                        g_score[neighbor] = tentative_g\n",
    "                        f_score = tentative_g + manhattan_distance(neighbor, target)\n",
    "                        heapq.heappush(open_set, (f_score, neighbor))\n",
    "                        came_from[neighbor] = current\n",
    "\n",
    "        # No path found\n",
    "        print(\"Path not found\")\n",
    "        return \"FAILURE\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b88595",
   "metadata": {},
   "source": [
    "## More Complex levels\n",
    "\n",
    "As the complexity of the enviorment increased, the agent had to navigate environments with additional challenges, such as locked doors, keys, and other obstacles. To address these complexities, we developed a **subgoal-based system** to enable dynamic online planning.\n",
    "\n",
    "### Subgoal System and Online Planning\n",
    "\n",
    "1. **Subgoal Identification**  \n",
    "   - For missions requiring multiple objectives (e.g., collecting a key and opening a door), the agent dynamically identifies subgoals based on the mission's requirements\n",
    "   - Subgoals are stored in the agent's memory until they are successfully completed\n",
    "\n",
    "2. **Online Planning**  \n",
    "   - The agent evaluates its current state and updates its plan in real time as new information is discovered, such as the location of a key or an unopened door\n",
    "   - This adaptive planning helps avoid deadlocks and ensures progress even in previously unseen or obstructed areas\n",
    "\n",
    "3. **Obstacle Handling**  \n",
    "   - Obstacles like locked doors are integrated online into the agent's internal map, in case they are necessary to proceed in completing current subgoal\n",
    "   - The agent evaluates complex scenarios and intelligently initializes a sequence of subgoals required to overcome these obstacles, ensuring progress toward the main subgoal\n",
    "\n",
    "4. **Inventory limit handling**  \n",
    "   - The agent's inventory is restricted to holding only one item. In certain levels, the agent must navigate confined environments with numerous obstacles while carrying a crucial object required to complete the main subgoal. This limitation compels the agent to dynamically create and prioritize multiple secondary subgoals, ensuring it can temporarily drop the item, clear the initial path, and retrieve it later to complete the mission successfully\n",
    "\n",
    "By introducing this subgoal-based online planning system, the agent can effectively tackle more complex environments, systematically addressing challenges and maintaining efficiency while solving tasks with multiple objectives.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbf240c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Subgoal:\n",
    "    def __init__(self, planner):\n",
    "        self.planner = planner\n",
    "\n",
    "    def __call__(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class GoNextToSubgoal(Subgoal): #This class is used to move the agent to a target position and the reason dictates how the agent will behave when it reaches the target\n",
    "    def __init__(self, planner, target, reason=\"GoNextTo\", target_pos=None):\n",
    "        super().__init__(planner)\n",
    "        self.target = target\n",
    "        self.reason = reason\n",
    "        self.target_pos = target_pos\n",
    "\n",
    "        self.action = None\n",
    "\n",
    "    def __call__(self):\n",
    "        \n",
    "        self.action = None\n",
    "\n",
    "        if self.target_pos is None: #If target position is not defined we request ExploreSubgoal to handle what target position to consider\n",
    "            self.planner.sub_goals.insert(0, ExploreSubgoal(self.planner, self.target, self.reason))\n",
    "            return self.planner.actions.done\n",
    "        \n",
    "        if self.reason == \"Explore\": #Continous scan for target even during exploration towards frontier to not waste steps if target is found\n",
    "            if self.planner.look_for_goal(self.target[0], self.target[1], self.target[2]) != None:\n",
    "                self.planner.prev_frontier = None\n",
    "                self.action = self.planner.actions.done\n",
    "            if self.planner.vis_mask[self.target_pos]:\n",
    "                self.action = self.planner.actions.done\n",
    "         \n",
    "        if self.reason == \"PutNext\": \n",
    "            if self.target[0] != 4:\n",
    "                prova_target = self.planner.look_for_goal(self.target[0], self.target[1], self.target[2])\n",
    "                neighbors = self.planner.neighbors(prova_target)\n",
    "                if (self.target not in neighbors):\n",
    "                    target = self.planner.find_closest_drop_cell(prova_target)\n",
    "                    self.target_pos = target\n",
    "\n",
    "        neighbors = self.planner.neighbors(self.target_pos)\n",
    "        if self.reason == \"Open\":\n",
    "            if self.planner.vis_obs[self.target_pos][2] == 2 or any(self.planner.vis_obs[n[0], n[1]][2] == 2 for n in neighbors): #Check if door we are supposed to open is locked\n",
    "                if self.planner.vis_obs[self.target_pos][2] == 2:\n",
    "                    color=self.planner.vis_obs[self.target_pos][1]\n",
    "                else:\n",
    "                    for n in neighbors:\n",
    "                        if self.planner.vis_obs[n[0], n[1]][2] == 2:\n",
    "                            color = self.planner.vis_obs[n][1]\n",
    "                if self.planner.carrying_object is not None: #Check if carrying object \n",
    "\n",
    "                    if self.planner.carrying_object[1] != color or self.planner.carrying_object[0] != 5: #Check if carrying object is not key we need\n",
    "                        self.planner.sub_goals.insert(0, GoNextToSubgoal(self.planner, [5,color,None], \"PickUp_Keep_important\")) #If not key we need we init a new subgoal to pick up the key\n",
    "\n",
    "                        return self.planner.actions.done\n",
    "                    \n",
    "                else:\n",
    "                    self.planner.sub_goals.insert(0, GoNextToSubgoal(self.planner, [5,color,None], \"PickUp_Keep_important\")) #If not carrying object we init a new subgoal to pick up the key\n",
    "\n",
    "                    return self.planner.actions.done\n",
    "                \n",
    "        if self.action is None:\n",
    "            self.action = self.planner.move_to_target(self.target_pos) #We call function to move towards target position\n",
    "\n",
    "        if self.action == \"FAILURE\": #If we get a failure we interrupt bot and stop environment\n",
    "            return \"FAILURE\"\n",
    "\n",
    "        if self.action == \"BLOCKED\": #Handles blocked frontal path\n",
    "\n",
    "            if self.planner.carrying: #Check if we are carrying \n",
    "                empty_cell = self.planner.find_closest_empty_cell(self.planner.pos)\n",
    "\n",
    "                if self.planner.carrying_target in self.planner.important_objects: #Check if we are carrying important object for next subgoal\n",
    "\n",
    "                    self.planner.save_path = self.planner.path #Save the current path we were following\n",
    "                    \n",
    "                    #Init subgoal where we drop important object and save coords\n",
    "                    #Init subgoal to pick up and move blocking object\n",
    "                    #Init subgoal to to return to dropped important item and pick it up again\n",
    "                    self.planner.sub_goals.insert(0, GoNextToSubgoal(self.planner, self.planner.carrying_target, \"PickUp_Keep_important\"))\n",
    "                    self.planner.sub_goals.insert(0, GoNextToSubgoal(self.planner, self.planner.target_in_cell(self.planner.path[0], self.target), \"PickUp_NoKeep_Move\", self.planner.cell_in_front()))\n",
    "                    self.planner.sub_goals.insert(0, GoNextToSubgoal(self.planner, self.planner.carrying_target, \"Drop_important\", empty_cell))\n",
    "                    \n",
    "                else:\n",
    "                    if self.reason == \"Drop\": #Check if item was supposed to be dropped somewhere specific\n",
    "\n",
    "                        self.planner.save_path.extend(self.planner.path) #Extends the current path with the new path for dropping item\n",
    "\n",
    "                        #Init subgoal where we drop object temporarily\n",
    "                        #Init subgoal to pick up and move blocking object\n",
    "                        #Init subgoal to to return to dropped item and pick it up again\n",
    "                        self.planner.sub_goals.insert(0, GoNextToSubgoal(self.planner, self.planner.carrying_target, \"PickUp_Keep\"))\n",
    "                        self.planner.sub_goals.insert(0, GoNextToSubgoal(self.planner, self.planner.target_in_cell(self.planner.path[0], self.target), \"PickUp_NoKeep_Move\", self.planner.cell_in_front()))\n",
    "                        self.planner.sub_goals.insert(0, GoNextToSubgoal(self.planner, self.planner.carrying_target, \"Drop\", empty_cell))\n",
    "                        \n",
    "                    else:\n",
    "                        self.planner.sub_goals.insert(0, GoNextToSubgoal(self.planner, self.target, \"Drop\", empty_cell))\n",
    "\n",
    "            else:\n",
    "                #If not carrying we init a new subgoal to pick up the object blocking our path\n",
    "                self.planner.sub_goals.insert(0, PickupSubgoal(self.planner, self.target))\n",
    "\n",
    "            return self.planner.actions.done\n",
    "        \n",
    "        if self.action == \"BLOCKED_SIDE\": #Handles blocked side path and we are carrying object\n",
    "\n",
    "            empty_cell = self.planner.find_closest_empty_cell(self.planner.pos)\n",
    "\n",
    "            if self.planner.carrying_target in self.planner.important_objects: #Check if we are carrying important object for next subgoal\n",
    "   \n",
    "                self.planner.save_path = self.planner.path #Save the current path we were following\n",
    "\n",
    "                #Init subgoal where we drop important object and save coords\n",
    "                #Init subgoal to pick up and move blocking object\n",
    "                #Init subgoal to to return to dropped important item and pick it up again\n",
    "                self.planner.sub_goals.insert(0, GoNextToSubgoal(self.planner, self.planner.carrying_target, \"PickUp_Keep_important\"))\n",
    "                self.planner.sub_goals.insert(0, GoNextToSubgoal(self.planner, self.planner.target_in_cell(self.planner.path[0], self.target), \"PickUp_NoKeep_Move\", self.planner.path[0]))\n",
    "                self.planner.sub_goals.insert(0, GoNextToSubgoal(self.planner, self.planner.carrying_target, \"Drop_important\", empty_cell))\n",
    "\n",
    "            else:\n",
    "                if self.reason == \"Drop\": #Check if item was supposed to be dropped somewhere specific\n",
    "                    \n",
    "                    self.planner.save_path.extend(self.planner.path)\n",
    "\n",
    "                    #Init subgoal where we drop object temporarily\n",
    "                    #Init subgoal to pick up and move blocking object\n",
    "                    #Init subgoal to to return to dropped item and pick it up again\n",
    "                    self.planner.sub_goals.insert(0, GoNextToSubgoal(self.planner, self.planner.carrying_target, \"PickUp_Keep\"))\n",
    "                    self.planner.sub_goals.insert(0, GoNextToSubgoal(self.planner, self.planner.target_in_cell(self.planner.path[0], self.target), \"PickUp_NoKeep_Move\", self.planner.path[0]))\n",
    "                    self.planner.sub_goals.insert(0, GoNextToSubgoal(self.planner, self.planner.carrying_target, \"Drop\", empty_cell))\n",
    "\n",
    "                else:\n",
    "                    #If carrying useless object we init a new subgoal to drop it\n",
    "                    self.planner.sub_goals.insert(0, GoNextToSubgoal(self.planner, self.target, \"Drop\", empty_cell))\n",
    "\n",
    "            return self.planner.actions.done \n",
    "\n",
    "        if self.action == \"OPEN DOOR\": #Handles open door subgoal\n",
    "            self.planner.sub_goals.insert(0, OpenSubgoal(self.planner))\n",
    "\n",
    "            return self.planner.actions.done\n",
    "        \n",
    "        if self.action == self.planner.actions.done: #If we reached target position we handle the reason for the subgoal\n",
    "            self.planner.sub_goals.pop(0)\n",
    "\n",
    "            if self.reason == \"PickUp_Keep\":\n",
    "                self.planner.sub_goals.insert(0, PickupSubgoal(self.planner, self.target))\n",
    "\n",
    "            elif self.reason == \"PickUp_NoKeep\": \n",
    "                self.planner.sub_goals.insert(0, DropSubgoal(self.planner))\n",
    "                self.planner.sub_goals.insert(0, PickupSubgoal(self.planner, self.target))\n",
    "\n",
    "            elif self.reason == \"PickUp_NoKeep_Move\": \n",
    "                empty_cell = self.planner.find_closest_empty_cell_avoiding_previous_path(self.planner.cell_in_front())\n",
    "                #We call avoid path funtion since we typically move the object to not block the path we need to bring another object through\n",
    "                self.planner.sub_goals.insert(0, GoNextToSubgoal(self.planner, self.target, \"Drop\", empty_cell))\n",
    "                self.planner.sub_goals.insert(0, PickupSubgoal(self.planner, self.target))\n",
    "\n",
    "            elif self.reason == \"PickUp_Keep_important\": \n",
    "                self.planner.sub_goals.insert(0, PickupSubgoal(self.planner, self.target))\n",
    "\n",
    "                if self.target not in self.planner.important_objects:\n",
    "                    self.planner.important_objects.append(self.target)\n",
    "\n",
    "            elif self.reason == \"Drop_important\":\n",
    "                self.planner.sub_goals.insert(0, DropSubgoal(self.planner))\n",
    "                self.planner.important_objects_coords.append(self.planner.cell_in_front())\n",
    "                \n",
    "            elif self.reason == \"PutNext\":\n",
    "                self.planner.important_objects.remove(self.planner.carrying_target) \n",
    "                self.planner.sub_goals.insert(0, DropSubgoal(self.planner))\n",
    "\n",
    "            elif self.reason == \"Open\":\n",
    "                self.planner.sub_goals.insert(0, OpenSubgoal(self.planner))\n",
    "\n",
    "            elif self.reason == \"Drop\":\n",
    "                self.planner.sub_goals.insert(0, DropSubgoal(self.planner))\n",
    "\n",
    "        return self.action\n",
    "            \n",
    "\n",
    "class OpenSubgoal(Subgoal):\n",
    "    def __init__(self, planner):\n",
    "        super().__init__(planner)\n",
    "        \n",
    "    def __call__(self):\n",
    "        if (self.planner.vis_obs[self.planner.cell_in_front()][2] == 0): #Handles opening an already opened door\n",
    "            action = self.planner.actions.toggle           \n",
    "        else:\n",
    "            action = self.planner.actions.toggle\n",
    "            self.planner.sub_goals.pop(0)\n",
    "            \n",
    "        return action    \n",
    "    \n",
    "    \n",
    "class PickupSubgoal(Subgoal):\n",
    "    def __init__(self, planner, target, reason = \"PickUp_Keep\"):\n",
    "        super().__init__(planner)\n",
    "        self.target = target\n",
    "        self.reason  = reason\n",
    "\n",
    "    def __call__(self):\n",
    "        if self.planner.carrying: #Handles the case where the agent is already carrying an object\n",
    "\n",
    "            self.planner.sub_goals.pop(0)\n",
    "            \n",
    "            empty_cell = self.planner.find_closest_empty_cell(self.planner.pos)\n",
    "            \n",
    "            #Init subgoal to drop object\n",
    "            #Init subgoal where we pass reason for picking up object\n",
    "            self.planner.sub_goals.insert(0, GoNextToSubgoal(self.planner, self.target, self.reason))\n",
    "            self.planner.sub_goals.insert(0, GoNextToSubgoal(self.planner, None, \"Drop\", empty_cell))\n",
    "            return self.planner.actions.done\n",
    "        \n",
    "        action = self.planner.actions.pickup\n",
    "        self.planner.carrying = True\n",
    "        self.planner.carrying_target = self.target\n",
    "        self.planner.carrying_object = self.planner.vis_obs[self.planner.cell_in_front()]\n",
    "\n",
    "        self.planner.sub_goals.pop(0)\n",
    "\n",
    "        return action\n",
    "\n",
    "\n",
    "class DropSubgoal(Subgoal):\n",
    "    def __init__(self, planner):\n",
    "        super().__init__(planner)\n",
    "\n",
    "    def __call__(self):\n",
    "\n",
    "        action = self.planner.actions.drop\n",
    "        self.planner.sub_goals.pop(0)\n",
    "\n",
    "        self.planner.carrying = False\n",
    "        self.planner.carrying_object = None\n",
    "        self.planner.carrying_target = None\n",
    "\n",
    "        return action\n",
    "    \n",
    "\n",
    "class ExploreSubgoal(Subgoal):\n",
    "    def __init__(self, planner, target, reason=\"GoNextTo\"):\n",
    "        super().__init__(planner)\n",
    "\n",
    "        self.target = target\n",
    "        self.target_pos = None\n",
    "        self.reason = reason\n",
    "\n",
    "        self.frontier = None\n",
    "        self.sub_goal_complete = False\n",
    "        self.action = None\n",
    "\n",
    "    def __call__(self):\n",
    "        self.target_pos = self.planner.look_for_goal(self.target[0], self.target[1], self.target[2]) #Look for target position\n",
    "\n",
    "        if self.target_pos is None: #Target isnt found we look for a frontier\n",
    "\n",
    "            self.frontier = self.planner.find_frontiers() \n",
    "\n",
    "            if self.frontier == self.planner.prev_frontier: #Avoids getting stuck in a loop calling the same frontier\n",
    "                self.frontier = self.planner.find_new_frontiers(self.frontier)\n",
    "\n",
    "            if self.frontier is None: #If no frontier is found we interrupt bot and stop environment\n",
    "                return \"FAILURE\"\n",
    "\n",
    "            neighbors = self.planner.neighbors(self.frontier)\n",
    "         \n",
    "            if any(self.planner.vis_obs[n[0], n[1]][2] == 2 for n in neighbors): #Check if frontier is behind a locked door\n",
    "                for n in neighbors:\n",
    "                    if self.planner.vis_obs[n[0], n[1]][2] == 2:\n",
    "                        target = n\n",
    "                self.planner.sub_goals.pop(0)\n",
    "                self.planner.prev_frontier = self.frontier\n",
    "\n",
    "                #Init subgoal to open door and eventually look for key\n",
    "                self.planner.sub_goals.insert(0, GoNextToSubgoal(self.planner, self.planner.door_in_cell(target), \"Open\", target))\n",
    "            \n",
    "            else:\n",
    "                self.planner.sub_goals.pop(0)\n",
    "                self.planner.prev_frontier = self.frontier\n",
    "\n",
    "                #Init subgoal to move towards frontier\n",
    "                self.planner.sub_goals.insert(0, GoNextToSubgoal(self.planner, self.target, \"Explore\", self.frontier))\n",
    "\n",
    "            return self.planner.actions.done\n",
    "        \n",
    "        else:\n",
    "\n",
    "            self.planner.sub_goals.pop(0)\n",
    "\n",
    "            \n",
    "            if self.reason == \"PutNext\":\n",
    "\n",
    "                #If we are supposed to put object next to target we find closest empty cell and consider it as target position\n",
    "                self.target_pos = self.planner.find_closest_drop_cell(self.target_pos)\n",
    "                self.planner.drop_pos = self.target_pos\n",
    "                self.planner.sub_goals[0].target_pos = self.target_pos\n",
    "\n",
    "            else:\n",
    "\n",
    "                #If target is found we move towards target position\n",
    "                self.planner.sub_goals[0].target_pos = self.target_pos\n",
    "\n",
    "            return self.planner.actions.done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88847104",
   "metadata": {},
   "source": [
    "## Our Agent vs BabyAI\n",
    "\n",
    "BabyAI is an intelligent agent implemented in the Minigrid libraries. It uses the \"Breath Deep Search\" to search the best path and the Manhattan distance to measure the step needed to reach the goal.\n",
    "\n",
    "We evaluated the performance of our agent against BabyAI by testing their ability to solve the environments provided by MiniGrid. The primary metric for comparison was the number of steps required to complete each task. The evaluation was conducted across 100 different seeds, with each seed encompassing all 92 BabyAI environments. Room layouts and obstacle placements were randomized for each run, and in some cases, the goal itself was altered, selected from a predefined pool of possible missions.\n",
    "\n",
    "Here our performance confronted with BabyAI:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56db3fa1-7890-4d88-85fe-8a2521615346",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python3 -m venv venv\n",
    "\n",
    "!source venv/bin/activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82c5ee91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/filippo-baglini/aif-project.git\n",
      "  Cloning https://github.com/filippo-baglini/aif-project.git to /tmp/pip-req-build-hz1107vg\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/filippo-baglini/aif-project.git /tmp/pip-req-build-hz1107vg\n",
      "  Resolved https://github.com/filippo-baglini/aif-project.git to commit eb72e5560f57117bb19db7f0a1669b1f36f77d40\n",
      "  Installing build dependencies ... \u001b[?2done\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting cloudpickle==3.1.0 (from aif-project==0.1.0)\n",
      "  Using cached cloudpickle-3.1.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting Farama-Notifications==0.0.4 (from aif-project==0.1.0)\n",
      "  Using cached Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n",
      "Collecting gymnasium==1.0.0 (from aif-project==0.1.0)\n",
      "  Using cached gymnasium-1.0.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting minigrid==3.0.0 (from aif-project==0.1.0)\n",
      "  Using cached minigrid-3.0.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting numpy==2.2.0 (from aif-project==0.1.0)\n",
      "  Using cached numpy-2.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Collecting pygame==2.6.1 (from aif-project==0.1.0)\n",
      "  Using cached pygame-2.6.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: typing_extensions==4.12.2 in ./env/lib/python3.12/site-packages (from aif-project==0.1.0) (4.12.2)\n",
      "Using cached cloudpickle-3.1.0-py3-none-any.whl (22 kB)\n",
      "Using cached Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
      "Using cached gymnasium-1.0.0-py3-none-any.whl (958 kB)\n",
      "Using cached minigrid-3.0.0-py3-none-any.whl (136 kB)\n",
      "Using cached numpy-2.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.1 MB)\n",
      "Using cached pygame-2.6.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)\n",
      "Building wheels for collected packages: aif-project\n",
      "  Building wheel for aif-project (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for aif-project: filename=aif_project-0.1.0-py3-none-any.whl size=2825 sha256=16361952be9932adfeae616068918a5c916fa6b7cbfb870c6207f0983efbb6da\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-k7o0x1ig/wheels/44/f3/65/8ef565deed78f0908ddf9768964482cee40b8727e42490f7b3\n",
      "Successfully built aif-project\n",
      "Installing collected packages: Farama-Notifications, pygame, numpy, cloudpickle, gymnasium, minigrid, aif-project\n",
      "Successfully installed Farama-Notifications-0.0.4 aif-project-0.1.0 cloudpickle-3.1.0 gymnasium-1.0.0 minigrid-3.0.0 numpy-2.2.0 pygame-2.6.1\n"
     ]
    }
   ],
   "source": [
    "# Install the required libraries   \n",
    "!pip install git+https://github.com/filippo-baglini/aif-project.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7eaecf5b-4224-4354-916d-51be74dc0de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                   Version\n",
      "------------------------- --------------\n",
      "aif-project               0.1.0\n",
      "anyio                     4.8.0\n",
      "argon2-cffi               23.1.0\n",
      "argon2-cffi-bindings      21.2.0\n",
      "arrow                     1.3.0\n",
      "asttokens                 3.0.0\n",
      "async-lru                 2.0.4\n",
      "attrs                     24.3.0\n",
      "babel                     2.16.0\n",
      "beautifulsoup4            4.12.3\n",
      "bleach                    6.2.0\n",
      "certifi                   2024.12.14\n",
      "cffi                      1.17.1\n",
      "charset-normalizer        3.4.1\n",
      "cloudpickle               3.1.0\n",
      "comm                      0.2.2\n",
      "debugpy                   1.8.12\n",
      "decorator                 5.1.1\n",
      "defusedxml                0.7.1\n",
      "executing                 2.1.0\n",
      "Farama-Notifications      0.0.4\n",
      "fastjsonschema            2.21.1\n",
      "fqdn                      1.5.1\n",
      "gymnasium                 1.0.0\n",
      "h11                       0.14.0\n",
      "httpcore                  1.0.7\n",
      "httpx                     0.28.1\n",
      "idna                      3.10\n",
      "ipykernel                 6.29.5\n",
      "ipython                   8.31.0\n",
      "isoduration               20.11.0\n",
      "jedi                      0.19.2\n",
      "Jinja2                    3.1.5\n",
      "json5                     0.10.0\n",
      "jsonpointer               3.0.0\n",
      "jsonschema                4.23.0\n",
      "jsonschema-specifications 2024.10.1\n",
      "jupyter_client            8.6.3\n",
      "jupyter_core              5.7.2\n",
      "jupyter-events            0.11.0\n",
      "jupyter-lsp               2.2.5\n",
      "jupyter_server            2.15.0\n",
      "jupyter_server_terminals  0.5.3\n",
      "jupyterlab                4.3.4\n",
      "jupyterlab_pygments       0.3.0\n",
      "jupyterlab_server         2.27.3\n",
      "MarkupSafe                3.0.2\n",
      "matplotlib-inline         0.1.7\n",
      "minigrid                  3.0.0\n",
      "mistune                   3.1.0\n",
      "nbclient                  0.10.2\n",
      "nbconvert                 7.16.5\n",
      "nbformat                  5.10.4\n",
      "nest-asyncio              1.6.0\n",
      "notebook                  7.3.2\n",
      "notebook_shim             0.2.4\n",
      "numpy                     2.2.0\n",
      "overrides                 7.7.0\n",
      "packaging                 24.2\n",
      "pandocfilters             1.5.1\n",
      "parso                     0.8.4\n",
      "pexpect                   4.9.0\n",
      "pip                       24.0\n",
      "platformdirs              4.3.6\n",
      "prometheus_client         0.21.1\n",
      "prompt_toolkit            3.0.48\n",
      "psutil                    6.1.1\n",
      "ptyprocess                0.7.0\n",
      "pure_eval                 0.2.3\n",
      "pycparser                 2.22\n",
      "pygame                    2.6.1\n",
      "Pygments                  2.19.1\n",
      "python-dateutil           2.9.0.post0\n",
      "python-json-logger        3.2.1\n",
      "PyYAML                    6.0.2\n",
      "pyzmq                     26.2.0\n",
      "referencing               0.36.1\n",
      "requests                  2.32.3\n",
      "rfc3339-validator         0.1.4\n",
      "rfc3986-validator         0.1.1\n",
      "rpds-py                   0.22.3\n",
      "Send2Trash                1.8.3\n",
      "setuptools                75.8.0\n",
      "six                       1.17.0\n",
      "sniffio                   1.3.1\n",
      "soupsieve                 2.6\n",
      "stack-data                0.6.3\n",
      "terminado                 0.18.1\n",
      "tinycss2                  1.4.0\n",
      "tornado                   6.4.2\n",
      "traitlets                 5.14.3\n",
      "types-python-dateutil     2.9.0.20241206\n",
      "typing_extensions         4.12.2\n",
      "uri-template              1.3.0\n",
      "urllib3                   2.3.0\n",
      "wcwidth                   0.2.13\n",
      "webcolors                 24.11.1\n",
      "webencodings              0.5.1\n",
      "websocket-client          1.8.0\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4603fe1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Define the path to the text file\u001b[39;00m\n\u001b[1;32m      4\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the path to the text file\n",
    "file_path = \"data.txt\"\n",
    "\n",
    "# Initialize lists to hold parsed data\n",
    "columns = []\n",
    "rows = []\n",
    "\n",
    "# Open the file and parse content\n",
    "with open(file_path, \"r\") as file:\n",
    "    for line_num, line in enumerate(file):\n",
    "        # Skip lines that are empty or contain dashes\n",
    "        if line.strip() == \"\" or \"-\" in line:\n",
    "            continue\n",
    "        \n",
    "        # Extract column headers\n",
    "        if line_num == 0:\n",
    "            columns = [col.strip() for col in line.split(\"   \") if col.strip()]\n",
    "        else:\n",
    "            # Extract row data\n",
    "            row = [item.strip() for item in line.split() if item.strip()]\n",
    "            rows.append(row)\n",
    "\n",
    "# Convert to a pandas DataFrame\n",
    "df = pd.DataFrame(rows, columns=columns)\n",
    "\n",
    "# Convert numeric columns to appropriate data types\n",
    "numeric_columns = df.columns.difference([\"Seed\"])  # Exclude Seed if it's not numeric\n",
    "for col in numeric_columns:\n",
    "    df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5606267",
   "metadata": {},
   "source": [
    "## Demonstration\n",
    "The following code demonstrates the execution of all the levels contained in the BabyAI enviroment tests.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33e74be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test dimostrativo della risoluzione di un livello:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14a0107-2dfe-4e34-bcd7-3dabe3ec397d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "# Get the absolute path of the parent directory of the project\n",
    "script_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "project_dir = os.path.abspath(os.path.join(script_dir, \"../\"))\n",
    "\n",
    "# Append the project directory to sys.path\n",
    "sys.path.append(project_dir)\n",
    "\n",
    "import gymnasium as gym\n",
    "\n",
    "from src.bot import Bot\n",
    "from src.goal_parser import *\n",
    "from minigrid.envs.babyai.core.verifier import *\n",
    "\n",
    "broken_bonus_envs = {\n",
    "    \"BabyAI-PutNextS5N2Carrying-v0\",\n",
    "    \"BabyAI-PutNextS6N3Carrying-v0\",\n",
    "    \"BabyAI-PutNextS7N4Carrying-v0\",\n",
    "    \"BabyAI-KeyInBox-v0\",\n",
    "}\n",
    "\n",
    "# get all babyai envs (except the broken ones)\n",
    "babyai_envs = []\n",
    "for k_i in gym.envs.registry.keys():\n",
    "    if k_i.split(\"-\")[0] == \"BabyAI\":\n",
    "        if k_i not in broken_bonus_envs:\n",
    "            babyai_envs.append(k_i)\n",
    "\n",
    "reward_list = []\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(len(babyai_envs))\n",
    "\n",
    "    for env_id in babyai_envs: # Loop through all environments\n",
    "        print(f\"Testing environment: {env_id}\")\n",
    "        env = gym.make(env_id, render_mode =\"human\", agent_pov = False) #Uncomment to test all the different levels with visuals\n",
    "        # env = gym.make(env_id) #Uncomment to test all the different levels without visuals\n",
    "        env.reset(seed=63)\n",
    "\n",
    "        print(env.unwrapped.mission) \n",
    "\n",
    "        bot = Bot(env)\n",
    "        max_steps = 500\n",
    "        num_steps = 0\n",
    "\n",
    "        for i in range (max_steps):\n",
    "            action = bot.take_action(env)  # Call the test function\n",
    "            if action == \"FAILURE\":\n",
    "                print(f\"LIVELLO FALLITO: {env}\")\n",
    "                break\n",
    "            \n",
    "            obs, reward, terminated, truncated, info = env.step(action)\n",
    "            num_steps += 1\n",
    "            \n",
    "            if terminated:\n",
    "                print(f\"PROVA NUM_STEPS: {num_steps}\")\n",
    "                reward_list.append((env_id, num_steps))\n",
    "                break\n",
    "        \n",
    "            env.render()\n",
    "            if i == (max_steps - 1):\n",
    "                print(\"MAX STEPS TAKEN\")\n",
    "        env.close()\n",
    "    \n",
    "    print(reward_list)\n",
    "    sum_steps = 0\n",
    "    for i in range(len(reward_list)):\n",
    "        sum_steps += reward_list[i][1] \n",
    "    print(sum_steps)\n",
    "    print(f\"Num Mission completed {len(reward_list)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
